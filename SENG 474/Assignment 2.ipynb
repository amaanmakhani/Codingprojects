{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data Set\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train datasets\n",
    "# This data set has already removed classes other than Class 5 and 7\n",
    "f = open(\"fashion-mnist_train.csv\")\n",
    "trainData = np.loadtxt(f, delimiter= \",\")\n",
    "# Seperate target and feadtures\n",
    "xTrain = trainData[:4000, 1:]\n",
    "yTrain = trainData[:4000, 0]\n",
    "# Pre-process data by rescaling inputs by 255\n",
    "xTrain = [[number/255 for number in group] for group in xTrain]\n",
    "\n",
    "# Load Test datasets\n",
    "# This data set has already removed classes other than Class 5 and 7\n",
    "f = open(\"fashion-mnist_test.csv\")\n",
    "testData = np.loadtxt(f, delimiter= \",\")\n",
    "# Seperate target and feadtures\n",
    "xTest = testData[:, 1:]\n",
    "yTest = testData[:, 0]\n",
    "# Pre-process data by rescaling inputs by 255\n",
    "xTest = [[number/255 for number in group] for group in xTest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misc Functions\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGraph(a, fa, b = [], fb = [], name = 'untitiled', xvalrange = 100, yvalrange = 100 + 4, xAxisTitle = \"\", title = \"\", digits = 5, single = False, label = False):\n",
    "    plt.clf()\n",
    "    if not single:\n",
    "        plt.plot(a, fa, linewidth=3.0, label='Training Data')\n",
    "        plt.plot(b, fb, linewidth=3.0, label='Test Data')\n",
    "    else:\n",
    "        plt.plot(a, fa, linewidth=3.0, label='Dataset')\n",
    "    ymin = min(fb) if not single else min(fa)\n",
    "    xpos = fb.index(ymin) if not single else fa.index(ymin)\n",
    "    xmin = b[xpos]  if not single else a[xpos] \n",
    "    plt.annotate('Minimum \\n(' + str(xmin) + ', ' + str(ymin)[0:digits] + ')', xy=(xmin, ymin), xytext=(xmin, ymin + 10), arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "    if label:\n",
    "        ymin = min(fa)\n",
    "        xpos = fa.index(ymin)\n",
    "        xmin = a[xpos] \n",
    "        plt.annotate('Minimum \\n(' + str(xmin) + ', ' + str(ymin)[0:digits] + ')', xy=(xmin, ymin), xytext=(xmin, ymin - 5), arrowprops=dict(facecolor='blue', shrink=0.05))\n",
    "    plt.xlabel(xAxisTitle)\n",
    "    plt.ylabel('Error (%)')\n",
    "    plt.xlim(0, xvalrange)\n",
    "    plt.ylim(0, yvalrange)\n",
    "    plt.title(title + ' vs. Error')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.savefig(name  + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(pred, test, debug = True):\n",
    "    if debug:\n",
    "        print(\"\\n-----------------------------------Metrics-----------------------------------\")\n",
    "        print('Mean Absolute Error:', metrics.mean_absolute_error(test, pred))\n",
    "        print('           Accuracy:',accuracy_score(test, pred))\n",
    "        print(\"\\n-----------------------------------Report------------------------------------\")\n",
    "        print(classification_report(test,pred))\n",
    "    return metrics.mean_absolute_error(test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeLogisticRegression(xTrain = [], yTrain = [], xTest = [], yTest = [], c = 1.0, pen = 'l2', train = True, test = True):\n",
    "    clf = LogisticRegression(C = 1/c, penalty = pen)\n",
    "    # Penalty: Used to specify the norm used in the penalization.\n",
    "    # C: Inverse of regularization strength; smaller values specify stronger regularization.\n",
    "    result = []\n",
    "    clf = clf.fit(xTrain, yTrain)\n",
    "    if train:\n",
    "        result.append(stats(clf.predict(xTrain), yTrain))\n",
    "    if test:\n",
    "        result.append(stats(clf.predict(xTest), yTest))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeSVM(xTrain = [], yTrain = [], xTest = [], yTest = [], c = 1.0, k = 'rbf', d = 3, g = 'scale', coef = 0.0, train = True, test = True):\n",
    "    clf = SVC(C = 1/c, kernel = k, degree = 3, gamma = g, coef0 = coef )\n",
    "    # C, Regularization parameter.The strength of the regularization is inversely proportional to C. \n",
    "        # Must be strictly positive. The penalty is a squared l2 penalty.\n",
    "    # kernel{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} , specifies the kernel type to be used in the algorithm.\n",
    "    # Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.\n",
    "    # Gamma{‘scale’, ‘auto’} or float, kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.\n",
    "    # coef0, Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.\n",
    "    result = []\n",
    "    clf = clf.fit(xTrain, yTrain)    \n",
    "    if train:\n",
    "        result.append(stats(clf.predict(xTrain), yTrain))\n",
    "    if test:\n",
    "        result.append(stats(clf.predict(xTest), yTest))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross-validation\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeKfold(X, Y, k):\n",
    "    result = []\n",
    "    kSize = int(len(X)/k)\n",
    "    i = 0\n",
    "    while i + kSize <= len(X):\n",
    "        result.append(X[i: i + kSize])\n",
    "        result.append(Y[i: i + kSize])\n",
    "        i += kSize\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSets(data, index):\n",
    "    result = []\n",
    "    for i in range(0, int(len(data)/2)):\n",
    "        if i != index:\n",
    "            if len(result) == 0:\n",
    "                result.append(list(data[2*i]))\n",
    "                result.append(list(data[2*i + 1]))\n",
    "            else:\n",
    "                result[0].extend(list(data[2*i]))\n",
    "                result[1].extend(list(data[2*i + 1]))\n",
    "    result.append(data[2 * index])\n",
    "    result.append(data[2 * index + 1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task One \n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "fa = []\n",
    "fb = []\n",
    "for i in range(0, 11):\n",
    "    error = executeLogisticRegression(xTrain, yTrain, xTest, yTest, c = 0.001*(3.5**i))\n",
    "    x.append(i)\n",
    "    fa.append(error[0] * 100)\n",
    "    fb.append(error[1] * 100)\n",
    "plotGraph(x, fa, x, fb, \"TaskOne\", xvalrange = 10, yvalrange = 18, xAxisTitle = \"Regularization Strength (0.001*3.5$^x$)\", title = \"Regularization Strength\", digits = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Two \n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "fa = []\n",
    "fb = []\n",
    "for i in range(0, 11):\n",
    "    error = executeSVM(xTrain, yTrain, xTest, yTest, k = 'linear', c =  0.0045*(3.2**i))\n",
    "    x.append(i)\n",
    "    fa.append(error[0] * 100)\n",
    "    fb.append(error[1] * 100)\n",
    "plotGraph(x, fa, x, fb, \"TaskTwo\", xvalrange = 10, yvalrange = 18, xAxisTitle = \"Regularization Strength (0.004*3.2$^x$)\", title = \"Regularization Strength\", digits = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Three \n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "yLR = []\n",
    "ySVM = []\n",
    "optimalRegularizationLG = 0\n",
    "optimalRegularizationSVM = 0\n",
    "minValidationError = np.inf\n",
    "fold = 8\n",
    "\n",
    "Validation = executeKfold(xTrain, yTrain, fold)\n",
    "for i in range(0, 11):\n",
    "    temp = 0\n",
    "    for k in range(0, fold):\n",
    "        regularizationStrength = 0.001*(3.5**i)\n",
    "        kFoldData = createSets(Validation, k)\n",
    "        error = executeLogisticRegression(kFoldData[0], kFoldData[1], kFoldData[2], kFoldData[3], c = regularizationStrength)\n",
    "        temp += error[1]\n",
    "    temp = temp/fold\n",
    "    if temp < minValidationError:\n",
    "        minValidationError = temp\n",
    "        optimalRegularizationLG = regularizationStrength\n",
    "    x.append(i)\n",
    "    yLR.append(temp * 100)\n",
    "\n",
    "minValidationError = np.inf\n",
    "Validation = executeKfold(xTrain, yTrain, fold)\n",
    "for i in range(0, 11):\n",
    "    temp = 0\n",
    "    for k in range(0, fold):\n",
    "        regularizationStrength = 0.0045*(3.2**i)\n",
    "        kFoldData = createSets(Validation, k)\n",
    "        error = executeSVM(kFoldData[0], kFoldData[1], kFoldData[2], kFoldData[3], k = 'linear', c = regularizationStrength)\n",
    "        temp += error[1]\n",
    "    temp = temp/fold\n",
    "    if temp < minValidationError:\n",
    "        minValidationError = temp\n",
    "        optimalRegularizationSVM = regularizationStrength\n",
    "    ySVM.append(temp * 100)\n",
    "    \n",
    "plotGraph(x, ySVM, x, yLR, \"TaskThree\", xvalrange = 10, yvalrange = 18, xAxisTitle = \"Regularization Strength Exponent\", title = \"Regularization Strength\", digits = 4, label = True)\n",
    "result = executeLogisticRegression(xTrain, yTrain, xTest, yTest, c = optimalRegularizationSVM, train = False)\n",
    "print(\"Optimized Logistic Regression error = \" + str(result[0]))\n",
    "result = executeSVM(xTrain, yTrain, xTest, yTest, c = optimalRegularizationSVM, k = 'linear', train = False)\n",
    "print(\"Optimized SVM error = \" + str(result[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Four \n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = []\n",
    "fb = []\n",
    "gammaValues = [0.0001, 0.01, 0.05, 0.1, 0.2, 0.3]\n",
    "fold = 8\n",
    "optmizedValues = {}\n",
    "optimalRegularizationSVM = 0\n",
    "\n",
    "Validation = executeKfold(xTrain, yTrain, fold)\n",
    "for gamma in gammaValues:\n",
    "    minValidationError = np.inf\n",
    "    currentValidationError = np.inf\n",
    "    for i in range(0, 11):\n",
    "        temp = 0\n",
    "        regularizationStrength =  0.0045*(3.2**i)\n",
    "        for k in range(0, fold):\n",
    "            kFoldData = createSets(Validation, k)\n",
    "            error = executeSVM(kFoldData[0], kFoldData[1], kFoldData[2], kFoldData[3], c = regularizationStrength, g = gamma)\n",
    "            temp += error[1]\n",
    "        temp = temp/fold\n",
    "        if temp < minValidationError:\n",
    "            minValidationError = temp\n",
    "            optimalRegularizationSVM = regularizationStrength\n",
    "        if minValidationError < currentValidationError:\n",
    "            optmizedValues[gamma] = optimalRegularizationSVM\n",
    "            currentValidationError = minValidationError\n",
    "    \n",
    "for gamma, regularization in optmizedValues.items():\n",
    "    error = executeSVM(xTrain, yTrain, xTest, yTest, g = gamma, c = regularization)\n",
    "    fa.append(error[0] * 100)\n",
    "    fb.append(error[1] * 100)\n",
    "print(optmizedValues)\n",
    "plotGraph(gammaValues, fa, gammaValues, fb, name = \"TaskFour\", xvalrange = max(gammaValues), yvalrange =  max(max(fa), max(fb)) + 6, xAxisTitle = \"γ\", title = \"Gamma\", digits = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
